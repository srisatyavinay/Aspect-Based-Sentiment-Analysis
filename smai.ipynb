{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.utils import shuffle\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json file into a list\n",
    "with open('./acsa-restaurant-large/acsa_train.json','rb') as f:\n",
    "    data1 = json.load(f)\n",
    "\n",
    "with open('./acsa-restaurant-large/acsa_test.json','rb') as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "sentence_data = [x['sentence'] for x in data1] + [x['sentence'] for x in data2]\n",
    "aspect_data = [x['aspect'] for x in data1] + [x['aspect'] for x in data2]\n",
    "sentiment_data = [x['sentiment'] for x in data1] + [x['sentiment'] for x in data2]\n",
    "\n",
    "sentence_data, aspect_data, sentiment_data = shuffle(sentence_data, aspect_data, sentiment_data)\n",
    "\n",
    "# print('Number of sentences: ', len(sentence_data))\n",
    "# print('Number of aspects: ', len(aspect_data))\n",
    "# print('Number of sentiments: ', len(sentiment_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = {}\n",
    "for example in sentence_data:\n",
    "    for word in example.split():\n",
    "        if word[-1] in ['.',',','!','?']:\n",
    "            word = word[:-1]\n",
    "        if word not in data_words:\n",
    "            data_words[word] = 0\n",
    "        else:\n",
    "            data_words[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_categories = {}\n",
    "for example in aspect_data:\n",
    "    for word in example.split():\n",
    "        if word[-1] in ['.',',','!','?']:\n",
    "            word = word[:-1]\n",
    "        if word not in aspect_categories:\n",
    "            aspect_categories[word] = 0\n",
    "        else:\n",
    "            aspect_categories[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6959\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(data_words))\n",
    "print(len(aspect_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load glove vectors\n",
    "glove_folder = os.path.join(os.getcwd(), 'glove_file')\n",
    "\n",
    "# get path of glove.6B.300d.txt file in test folder\n",
    "glove_file = os.path.join(glove_folder, 'glove.6B.300d.txt')\n",
    "\n",
    "def load_glove_vectors(glove_file):\n",
    "    with open(glove_file, 'r', encoding=\"utf8\") as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "            \n",
    "    with open(glove_file, 'r', encoding=\"utf8\") as f:\n",
    "        embs = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "\n",
    "            if curr_word in data_words:\n",
    "                try:\n",
    "                    embedding = np.array([float(value) for value in line[1:]])\n",
    "                    embs[curr_word] = embedding\n",
    "                except:\n",
    "                    print('error loading embedding')\n",
    "    return words, word_to_vec_map, embs\n",
    "\n",
    "glove_words, glove_word_to_vec_map, data_word_to_vec_map = load_glove_vectors(glove_file)\n",
    "# print(len(words))\n",
    "# print(len(word_to_vec_map))\n",
    "# print(word_to_vec_map['the'])\n",
    "# print(word_to_vec_map['the'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspect_catogories_glove_embedding(glove_file):\n",
    "    with open(glove_file, 'r', encoding=\"utf8\") as f:\n",
    "        embs = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "\n",
    "            if curr_word in aspect_categories:\n",
    "                try:\n",
    "                    embedding = np.array([float(value) for value in line[1:]])\n",
    "                    embs[curr_word] = embedding\n",
    "                except:\n",
    "                    print('error loading embedding')\n",
    "    return embs\n",
    "\n",
    "aspect_catogories_to_vec_map = get_aspect_catogories_glove_embedding(glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_word_vector = np.mean(list(glove_word_to_vec_map.values()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6959\n",
      "5449\n",
      "1510\n"
     ]
    }
   ],
   "source": [
    "print(len(data_words))\n",
    "print(len(data_word_to_vec_map))\n",
    "missing_words = len(data_words) - len(data_word_to_vec_map)\n",
    "print(missing_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(aspect_categories))\n",
    "print(len(aspect_catogories_to_vec_map))\n",
    "missing_aspect_categories_words = len(aspect_catogories_to_vec_map) - len(aspect_categories)\n",
    "print(missing_aspect_categories_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = []\n",
    "idx2word = []\n",
    "word2idx = {}\n",
    "embedding_matrix.append(np.zeros(300)) # this will be our zero padding for the network\n",
    "idx2word.append('')\n",
    "word2idx[''] = 0\n",
    "for i, (word, emb) in enumerate(data_word_to_vec_map.items()):\n",
    "    embedding_matrix.append(emb)\n",
    "    idx2word.append(word)\n",
    "    word2idx[word] = i + 1\n",
    "    # word2idx[word] = i\n",
    "embedding_matrix = np.asarray(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_embedding_matrix = []\n",
    "ac_idx2word = []\n",
    "ac_word2idx = {}\n",
    "# ac_embedding_matrix.append(np.zeros(300)) # this will be our zero padding for the network\n",
    "# ac_idx2word.append('')\n",
    "# ac_word2idx[''] = 0\n",
    "for i, (word, emb) in enumerate(aspect_catogories_to_vec_map.items()):\n",
    "    ac_embedding_matrix.append(emb)\n",
    "    ac_idx2word.append(word)\n",
    "    # ac_word2idx[word] = i + 1\n",
    "    ac_word2idx[word] = i\n",
    "ac_embedding_matrix = np.asarray(ac_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "for example in sentence_data:\n",
    "    temp = []\n",
    "    for word in example.split():\n",
    "        if word[-1] in ['.',',','!','?']:\n",
    "            word = word[:-1]\n",
    "        if word in word2idx:\n",
    "            temp.append(word2idx[word])\n",
    "    # if len(temp) == 0:\n",
    "    #     print(example)\n",
    "    x_train.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_train = []\n",
    "for example in aspect_data:\n",
    "    temp = []\n",
    "    for word in example.split():\n",
    "        if word[-1] in ['.',',','!','?']:\n",
    "            word = word[:-1]\n",
    "        if word in ac_word2idx:\n",
    "            temp.append(ac_word2idx[word])\n",
    "    # if len(temp) == 0:\n",
    "    #     print(example)\n",
    "    ac_train.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_train = np.asarray(ac_train, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7091,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7091, 1)\n"
     ]
    }
   ],
   "source": [
    "print(ac_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 0\n",
    "min_length = 1000\n",
    "for example in x_train:\n",
    "    if len(example) > max_length:\n",
    "        max_length = len(example)\n",
    "    if len(example) < min_length:\n",
    "        min_length = len(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(max_length)\n",
    "print(min_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.753631363700466\n"
     ]
    }
   ],
   "source": [
    "total_length = 0\n",
    "for i in range(len(x_train)):\n",
    "    total_length += len(x_train[i])\n",
    "avg_length = total_length / len(x_train)\n",
    "print(avg_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    x_train[i] = np.pad(x_train[i], (max_length - len(x_train[i]), 0), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data = []\n",
    "for x in x_train:\n",
    "    x_train_data.append([k for k in x])\n",
    "\n",
    "x_train_data = np.array(x_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_train_data = []\n",
    "for x in ac_train:\n",
    "    ac_train_data.append([k for k in x])\n",
    "\n",
    "ac_train_data = np.array(ac_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5450, 300)\n",
      "5449\n",
      "6959\n",
      "(7091,)\n",
      "(7091,)\n",
      "(8, 300)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)\n",
    "print(len(data_word_to_vec_map))\n",
    "print(len(data_words))\n",
    "print(np.array(sentence_data).shape)\n",
    "print(np.array(aspect_data).shape)\n",
    "print(ac_embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7091, 64)\n",
      "(7091, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_data.shape)\n",
    "print(ac_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5450, 300)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Gate_Aspect_Text(nn.Module):\n",
    "    def __init__(self, embedding_matrix, class_num, kernel_num, kernel_sizes, aspect_matrix):\n",
    "        super(CNN_Gate_Aspect_Text, self).__init__()\n",
    "        # self.args = args\n",
    "        \n",
    "        V = embedding_matrix.shape[0]\n",
    "        D = embedding_matrix.shape[1]\n",
    "        C = class_num\n",
    "        A = aspect_matrix.shape[0]\n",
    "\n",
    "        Co = kernel_num\n",
    "        Ks = kernel_sizes\n",
    "\n",
    "        self.embed = nn.Embedding(V, D)\n",
    "        self.embed.load_state_dict({'weight': torch.tensor(embedding_matrix)})\n",
    "        # self.embed.weight = nn.Parameter(embedding_matrix, requires_grad=True)\n",
    "        self.embed.weight.requires_grad = True\n",
    "\n",
    "        self.aspect_embed = nn.Embedding(A, aspect_matrix.shape[1])\n",
    "        self.aspect_embed.load_state_dict({'weight':  torch.tensor(aspect_matrix)})\n",
    "        # self.aspect_embed.weight = nn.Parameter(aspect_matrix, requires_grad=True)\n",
    "        self.aspect_embed.weight.requires_grad = True\n",
    "\n",
    "        self.convs1 = nn.ModuleList([nn.Conv1d(D, Co, K) for K in Ks])\n",
    "        self.convs2 = nn.ModuleList([nn.Conv1d(D, Co, K) for K in Ks])\n",
    "\n",
    "        self.fc1 = nn.Linear(len(Ks)*Co, C)\n",
    "        self.fc_aspect = nn.Linear(aspect_matrix.shape[1], Co)\n",
    "\n",
    "    def forward(self, feature, aspect):\n",
    "        feature = self.embed(feature)  # (N, L, D)\n",
    "        aspect_v = self.aspect_embed(aspect)  # (N, L', D)\n",
    "        aspect_v = aspect_v.sum(1) / aspect_v.size(1)\n",
    "\n",
    "        x = [F.tanh(conv(feature.transpose(1, 2))) for conv in self.convs1]  # [(N,Co,L), ...]*len(Ks)\n",
    "        y = [F.relu(conv(feature.transpose(1, 2)) + self.fc_aspect(aspect_v).unsqueeze(2)) for conv in self.convs2]\n",
    "        x = [i*j for i, j in zip(x, y)]\n",
    "\n",
    "        # pooling method\n",
    "        x0 = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N,Co), ...]*len(Ks)\n",
    "        x0 = [i.view(i.size(0), -1) for i in x0]\n",
    "\n",
    "        x0 = torch.cat(x0, 1)\n",
    "        logit = self.fc1(x0)  # (N,C)\n",
    "        return logit, x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'negative': 1878, 'positive': 4215, 'neutral': 998}\n",
      "(7091,)\n"
     ]
    }
   ],
   "source": [
    "sentiments = {}\n",
    "\n",
    "# get unique sentiments in sentiment data\n",
    "for sentiment in sentiment_data:\n",
    "    if sentiment not in sentiments:\n",
    "        sentiments[sentiment] = 1\n",
    "    else:\n",
    "        sentiments[sentiment] += 1\n",
    "\n",
    "print(sentiments)\n",
    "\n",
    "sentiment_input = []\n",
    "for sentiment in sentiment_data:\n",
    "    if sentiment == 'positive':\n",
    "        sentiment_input.append(2)\n",
    "    elif sentiment == 'negative':\n",
    "        sentiment_input.append(0)\n",
    "    else:\n",
    "        sentiment_input.append(1)\n",
    "\n",
    "sentiment_input = np.array(sentiment_input)\n",
    "print(sentiment_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = CustomImageDataset(x_train_data, labels)\n",
    "\n",
    "train_length = int(len(sentence_data) * 0.8) # 80% training data, 20% test data\n",
    "test_length = len(sentence_data) - train_length\n",
    "\n",
    "# print(x_train_data.shape)\n",
    "\n",
    "# concatenate the x_train_data, ac_train_data and sentiment_input\n",
    "x_train_data = np.concatenate((x_train_data, ac_train_data), axis=1)\n",
    "# print(x_train_data.shape)\n",
    "x_train_data = np.concatenate((x_train_data, sentiment_input.reshape(-1, 1)), axis=1)\n",
    "\n",
    "# print(x_train_data.shape)\n",
    "\n",
    "\n",
    "\n",
    "# print(len(x_train_dataloader) * batch_size)\n",
    "# print(len(y_test_dataloader) * batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5672, 66)\n"
     ]
    }
   ],
   "source": [
    "# split x_train_data into training and test data using train_test_split\n",
    "x_train, x_test = train_test_split(x_train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 66])\n",
      "torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "# x_train = torch.tensor(x_train.astype('float64')).to(torch.int64)\n",
    "train_batches = DataLoader(x_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# for data in train_batches:\n",
    "#     # print(data)\n",
    "#     # break\n",
    "# # convert data to int tensor\n",
    "#     # data = data.to(torch.int64)\n",
    "#     print(data.shape)\n",
    "#     print(data[:, :-2].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x32 and 300x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\srisa\\Desktop\\Desktop files\\Project\\SMAI-Project-Team28\\smai.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X51sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m                 \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m'\u001b[39m, epoch, \u001b[39m'\u001b[39m\u001b[39mBatch: \u001b[39m\u001b[39m'\u001b[39m, i, \u001b[39m'\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m.\u001b[39mitem())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X51sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X51sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m model \u001b[39m=\u001b[39m train()\n",
      "\u001b[1;32mc:\\Users\\srisa\\Desktop\\Desktop files\\Project\\SMAI-Project-Team28\\smai.ipynb Cell 34\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X51sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X51sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# model.zero_grad()\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X51sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m logit, x, y \u001b[39m=\u001b[39m model(sentence, aspect)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X51sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_function(logit, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X51sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\srisa\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\srisa\\Desktop\\Desktop files\\Project\\SMAI-Project-Team28\\smai.ipynb Cell 34\u001b[0m in \u001b[0;36mCNN_Gate_Aspect_Text.forward\u001b[1;34m(self, feature, aspect)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X51sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m aspect_v \u001b[39m=\u001b[39m aspect_v\u001b[39m.\u001b[39msum(\u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m aspect_v\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X51sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m x \u001b[39m=\u001b[39m [F\u001b[39m.\u001b[39mtanh(conv(feature\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m))) \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs1]  \u001b[39m# [(N,Co,L), ...]*len(Ks)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X51sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m y \u001b[39m=\u001b[39m [F\u001b[39m.\u001b[39mrelu(conv(feature\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_aspect(aspect_v)\u001b[39m.\u001b[39munsqueeze(\u001b[39m2\u001b[39m)) \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs2]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X51sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m x \u001b[39m=\u001b[39m [i\u001b[39m*\u001b[39mj \u001b[39mfor\u001b[39;00m i, j \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(x, y)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X51sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# pooling method\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\srisa\\Desktop\\Desktop files\\Project\\SMAI-Project-Team28\\smai.ipynb Cell 34\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X51sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m aspect_v \u001b[39m=\u001b[39m aspect_v\u001b[39m.\u001b[39msum(\u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m aspect_v\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X51sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m x \u001b[39m=\u001b[39m [F\u001b[39m.\u001b[39mtanh(conv(feature\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m))) \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs1]  \u001b[39m# [(N,Co,L), ...]*len(Ks)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X51sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m y \u001b[39m=\u001b[39m [F\u001b[39m.\u001b[39mrelu(conv(feature\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc_aspect(aspect_v)\u001b[39m.\u001b[39munsqueeze(\u001b[39m2\u001b[39m)) \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs2]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X51sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m x \u001b[39m=\u001b[39m [i\u001b[39m*\u001b[39mj \u001b[39mfor\u001b[39;00m i, j \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(x, y)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X51sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# pooling method\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\srisa\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\srisa\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x32 and 300x100)"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    model = CNN_Gate_Aspect_Text(embedding_matrix, 3, 100, [3, 4, 5], ac_embedding_matrix)\n",
    "    # model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        for i, data in enumerate(train_batches):\n",
    "            sentence = data[:, :-2]\n",
    "            aspect = data[:, -2]\n",
    "            sentiment = data[:, -1]\n",
    "\n",
    "            # x = x.to(device)\n",
    "            # y = y.to(device)\n",
    "            # optimizer.zero_grad()\n",
    "            model.zero_grad()\n",
    "            # model.zero_grad()\n",
    "            logit, x, y = model(sentence, aspect)\n",
    "            loss = loss_function(logit, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print('Epoch: ', epoch, 'Batch: ', i, 'Loss: ', loss.item())\n",
    "    return model\n",
    "\n",
    "model = train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "063993497d7afc17216208e6d2fa098ad08ff0cdca94ee4cdde88ee1996574e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
