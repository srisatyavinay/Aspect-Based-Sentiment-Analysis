{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.utils import shuffle\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json file into a list\n",
    "with open('./acsa-restaurant-large/acsa_train.json','rb') as f:\n",
    "    data1 = json.load(f)\n",
    "\n",
    "with open('./acsa-restaurant-large/acsa_test.json','rb') as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "sentence_data = [x['sentence'] for x in data1] + [x['sentence'] for x in data2]\n",
    "aspect_data = [x['aspect'] for x in data1] + [x['aspect'] for x in data2]\n",
    "sentiment_data = [x['sentiment'] for x in data1] + [x['sentiment'] for x in data2]\n",
    "\n",
    "sentence_data, aspect_data, sentiment_data = shuffle(sentence_data, aspect_data, sentiment_data)\n",
    "\n",
    "# print('Number of sentences: ', len(sentence_data))\n",
    "# print('Number of aspects: ', len(aspect_data))\n",
    "# print('Number of sentiments: ', len(sentiment_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = {}\n",
    "for example in sentence_data:\n",
    "    for word in example.split():\n",
    "        if word[-1] in ['.',',','!','?']:\n",
    "            word = word[:-1]\n",
    "        if word not in data_words:\n",
    "            data_words[word] = 0\n",
    "        else:\n",
    "            data_words[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_categories = {}\n",
    "for example in aspect_data:\n",
    "    for word in example.split():\n",
    "        if word[-1] in ['.',',','!','?']:\n",
    "            word = word[:-1]\n",
    "        if word not in aspect_categories:\n",
    "            aspect_categories[word] = 0\n",
    "        else:\n",
    "            aspect_categories[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6959\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(data_words))\n",
    "print(len(aspect_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load glove vectors\n",
    "glove_folder = os.path.join(os.getcwd(), 'glove_file')\n",
    "\n",
    "# get path of glove.6B.300d.txt file in test folder\n",
    "glove_file = os.path.join(glove_folder, 'glove.6B.300d.txt')\n",
    "\n",
    "def load_glove_vectors(glove_file):\n",
    "    with open(glove_file, 'r', encoding=\"utf8\") as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "            \n",
    "    with open(glove_file, 'r', encoding=\"utf8\") as f:\n",
    "        embs = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "\n",
    "            if curr_word in data_words:\n",
    "                try:\n",
    "                    embedding = np.array([float(value) for value in line[1:]])\n",
    "                    embs[curr_word] = embedding\n",
    "                except:\n",
    "                    print('error loading embedding')\n",
    "    return words, word_to_vec_map, embs\n",
    "\n",
    "glove_words, glove_word_to_vec_map, data_word_to_vec_map = load_glove_vectors(glove_file)\n",
    "# print(len(words))\n",
    "# print(len(word_to_vec_map))\n",
    "# print(word_to_vec_map['the'])\n",
    "# print(word_to_vec_map['the'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspect_catogories_glove_embedding(glove_file):\n",
    "    with open(glove_file, 'r', encoding=\"utf8\") as f:\n",
    "        embs = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "\n",
    "            if curr_word in aspect_categories:\n",
    "                try:\n",
    "                    embedding = np.array([float(value) for value in line[1:]])\n",
    "                    embs[curr_word] = embedding\n",
    "                except:\n",
    "                    print('error loading embedding')\n",
    "    return embs\n",
    "\n",
    "aspect_catogories_to_vec_map = get_aspect_catogories_glove_embedding(glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_word_vector = np.mean(list(glove_word_to_vec_map.values()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6959\n",
      "5449\n",
      "1510\n"
     ]
    }
   ],
   "source": [
    "print(len(data_words))\n",
    "print(len(data_word_to_vec_map))\n",
    "missing_words = len(data_words) - len(data_word_to_vec_map)\n",
    "print(missing_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(aspect_categories))\n",
    "print(len(aspect_catogories_to_vec_map))\n",
    "missing_aspect_categories_words = len(aspect_catogories_to_vec_map) - len(aspect_categories)\n",
    "print(missing_aspect_categories_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = []\n",
    "idx2word = []\n",
    "word2idx = {}\n",
    "embedding_matrix.append(np.zeros(300)) # this will be our zero padding for the network\n",
    "idx2word.append('')\n",
    "word2idx[''] = 0\n",
    "for i, (word, emb) in enumerate(data_word_to_vec_map.items()):\n",
    "    embedding_matrix.append(emb)\n",
    "    idx2word.append(word)\n",
    "    word2idx[word] = i + 1\n",
    "    # word2idx[word] = i\n",
    "embedding_matrix = np.asarray(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_embedding_matrix = []\n",
    "ac_idx2word = []\n",
    "ac_word2idx = {}\n",
    "# ac_embedding_matrix.append(np.zeros(300)) # this will be our zero padding for the network\n",
    "# ac_idx2word.append('')\n",
    "# ac_word2idx[''] = 0\n",
    "for i, (word, emb) in enumerate(aspect_catogories_to_vec_map.items()):\n",
    "    ac_embedding_matrix.append(emb)\n",
    "    ac_idx2word.append(word)\n",
    "    # ac_word2idx[word] = i + 1\n",
    "    ac_word2idx[word] = i\n",
    "ac_embedding_matrix = np.asarray(ac_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "for example in sentence_data:\n",
    "    temp = []\n",
    "    for word in example.split():\n",
    "        if word[-1] in ['.',',','!','?']:\n",
    "            word = word[:-1]\n",
    "        if word in word2idx:\n",
    "            temp.append(word2idx[word])\n",
    "    # if len(temp) == 0:\n",
    "    #     print(example)\n",
    "    x_train.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_train = []\n",
    "for example in aspect_data:\n",
    "    temp = []\n",
    "    for word in example.split():\n",
    "        if word[-1] in ['.',',','!','?']:\n",
    "            word = word[:-1]\n",
    "        if word in ac_word2idx:\n",
    "            temp.append(ac_word2idx[word])\n",
    "    # if len(temp) == 0:\n",
    "    #     print(example)\n",
    "    ac_train.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_train = np.asarray(ac_train, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7091,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7091, 1)\n"
     ]
    }
   ],
   "source": [
    "print(ac_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 0\n",
    "min_length = 1000\n",
    "for example in x_train:\n",
    "    if len(example) > max_length:\n",
    "        max_length = len(example)\n",
    "    if len(example) < min_length:\n",
    "        min_length = len(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(max_length)\n",
    "print(min_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.753631363700466\n"
     ]
    }
   ],
   "source": [
    "total_length = 0\n",
    "for i in range(len(x_train)):\n",
    "    total_length += len(x_train[i])\n",
    "avg_length = total_length / len(x_train)\n",
    "print(avg_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    x_train[i] = np.pad(x_train[i], (max_length - len(x_train[i]), 0), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data = []\n",
    "for x in x_train:\n",
    "    x_train_data.append([k for k in x])\n",
    "\n",
    "x_train_data = np.array(x_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_train_data = []\n",
    "for x in ac_train:\n",
    "    ac_train_data.append([k for k in x])\n",
    "\n",
    "ac_train_data = np.array(ac_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5450, 300)\n",
      "5449\n",
      "6959\n",
      "(7091,)\n",
      "(7091,)\n",
      "(8, 300)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)\n",
    "print(len(data_word_to_vec_map))\n",
    "print(len(data_words))\n",
    "print(np.array(sentence_data).shape)\n",
    "print(np.array(aspect_data).shape)\n",
    "print(ac_embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7091, 64)\n",
      "(7091, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_data.shape)\n",
    "print(ac_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5450, 300)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Gate_Aspect_Text(nn.Module):\n",
    "    def __init__(self, embedding_matrix, class_num, kernel_num, kernel_sizes, aspect_matrix):\n",
    "        super(CNN_Gate_Aspect_Text, self).__init__()\n",
    "        # self.args = args\n",
    "        \n",
    "        V = embedding_matrix.shape[0]\n",
    "        D = embedding_matrix.shape[1]\n",
    "        C = class_num\n",
    "        A = aspect_matrix.shape[0]\n",
    "\n",
    "        Co = kernel_num\n",
    "        Ks = kernel_sizes\n",
    "\n",
    "        self.embed = nn.Embedding(V, D)\n",
    "        self.embed.load_state_dict({'weight': torch.tensor(embedding_matrix)})\n",
    "        # self.embed.weight = nn.Parameter(embedding_matrix, requires_grad=True)\n",
    "        self.embed.weight.requires_grad = True\n",
    "\n",
    "        self.aspect_embed = nn.Embedding(A, aspect_matrix.shape[1])\n",
    "        self.aspect_embed.load_state_dict({'weight':  torch.tensor(aspect_matrix)})\n",
    "        # self.aspect_embed.weight = nn.Parameter(aspect_matrix, requires_grad=True)\n",
    "        self.aspect_embed.weight.requires_grad = True\n",
    "\n",
    "        self.convs1 = nn.ModuleList([nn.Conv1d(D, Co, K) for K in Ks])\n",
    "        self.convs2 = nn.ModuleList([nn.Conv1d(D, Co, K) for K in Ks])\n",
    "\n",
    "        self.fc1 = nn.Linear(len(Ks)*Co, C)\n",
    "        self.fc_aspect = nn.Linear(aspect_matrix.shape[1], Co)\n",
    "\n",
    "    def forward(self, feature, aspect):\n",
    "        feature = self.embed(feature) # (N, L, D)\n",
    "        aspect_v = self.aspect_embed(aspect)  # (N, L', D)\n",
    "        # aspect_v = aspect_v.sum(1) / aspect_v.size(1)\n",
    "\n",
    "        x = [F.tanh(conv(feature.transpose(1, 2))) for conv in self.convs1]  # [(N,Co,L), ...]*len(Ks)\n",
    "        y = [F.relu(conv(feature.transpose(1, 2)) + self.fc_aspect(aspect_v).unsqueeze(2)) for conv in self.convs2]\n",
    "        x = [i*j for i, j in zip(x, y)]\n",
    "\n",
    "        # pooling method\n",
    "        x0 = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N,Co), ...]*len(Ks)\n",
    "        x0 = [i.view(i.size(0), -1) for i in x0]\n",
    "\n",
    "        x0 = torch.cat(x0, 1)\n",
    "        logit = self.fc1(x0)  # (N,C)\n",
    "        return logit, x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neutral': 998, 'positive': 4215, 'negative': 1878}\n",
      "(7091,)\n"
     ]
    }
   ],
   "source": [
    "sentiments = {}\n",
    "\n",
    "# get unique sentiments in sentiment data\n",
    "for sentiment in sentiment_data:\n",
    "    if sentiment not in sentiments:\n",
    "        sentiments[sentiment] = 1\n",
    "    else:\n",
    "        sentiments[sentiment] += 1\n",
    "\n",
    "print(sentiments)\n",
    "\n",
    "sentiment_input = []\n",
    "for sentiment in sentiment_data:\n",
    "    if sentiment == 'positive':\n",
    "        sentiment_input.append(2)\n",
    "    elif sentiment == 'negative':\n",
    "        sentiment_input.append(0)\n",
    "    else:\n",
    "        sentiment_input.append(1)\n",
    "\n",
    "sentiment_input = np.array(sentiment_input)\n",
    "print(sentiment_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = CustomImageDataset(x_train_data, labels)\n",
    "\n",
    "train_length = int(len(sentence_data) * 0.8) # 80% training data, 20% test data\n",
    "test_length = len(sentence_data) - train_length\n",
    "\n",
    "# print(x_train_data.shape)\n",
    "\n",
    "# concatenate the x_train_data, ac_train_data and sentiment_input\n",
    "x_train_data = np.concatenate((x_train_data, ac_train_data), axis=1)\n",
    "# print(x_train_data.shape)\n",
    "x_train_data = np.concatenate((x_train_data, sentiment_input.reshape(-1, 1)), axis=1)\n",
    "\n",
    "# print(x_train_data.shape)\n",
    "\n",
    "\n",
    "\n",
    "# print(len(x_train_dataloader) * batch_size)\n",
    "# print(len(y_test_dataloader) * batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5672, 66)\n"
     ]
    }
   ],
   "source": [
    "# split x_train_data into training and test data using train_test_split\n",
    "x_train, x_test = train_test_split(x_train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# x_train = torch.tensor(x_train.astype('float64')).to(torch.int64)\n",
    "train_batches = DataLoader(torch.Tensor(x_train).to(dtype=torch.long), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# for data in train_batches:\n",
    "#     # print(data)\n",
    "#     # break\n",
    "# # convert data to int tensor\n",
    "#     # data = data.to(torch.int64)\n",
    "#     print(data.shape)\n",
    "#     print(data[:, :-2].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_string(tokens):  # Convert tokens back into their sting value\n",
    "    words = [idx2word[token] for token in tokens]\n",
    "    text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srisa\\AppData\\Local\\Temp\\ipykernel_9192\\2460389490.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.embed.load_state_dict({'weight': torch.tensor(embedding_matrix)})\n",
      "C:\\Users\\srisa\\AppData\\Local\\Temp\\ipykernel_9192\\2460389490.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.aspect_embed.load_state_dict({'weight':  torch.tensor(aspect_matrix)})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Batch:  0 Loss:  1.0999795198440552\n",
      "Epoch:  0 Batch:  100 Loss:  0.6852039694786072\n",
      "Epoch:  1 Batch:  0 Loss:  0.2715294063091278\n",
      "Epoch:  1 Batch:  100 Loss:  0.5342783331871033\n",
      "Epoch:  2 Batch:  0 Loss:  0.2274438738822937\n",
      "Epoch:  2 Batch:  100 Loss:  0.2654220461845398\n",
      "Epoch:  3 Batch:  0 Loss:  0.12264885008335114\n",
      "Epoch:  3 Batch:  100 Loss:  0.22132663428783417\n",
      "Epoch:  4 Batch:  0 Loss:  0.12209124863147736\n",
      "Epoch:  4 Batch:  100 Loss:  0.1999904215335846\n",
      "Epoch:  5 Batch:  0 Loss:  0.043819691985845566\n",
      "Epoch:  5 Batch:  100 Loss:  0.1051882803440094\n",
      "Epoch:  6 Batch:  0 Loss:  0.07469876110553741\n",
      "Epoch:  6 Batch:  100 Loss:  0.04391816630959511\n",
      "Epoch:  7 Batch:  0 Loss:  0.028147971257567406\n",
      "Epoch:  7 Batch:  100 Loss:  0.036731380969285965\n",
      "Epoch:  8 Batch:  0 Loss:  0.03281756490468979\n",
      "Epoch:  8 Batch:  100 Loss:  0.04698498547077179\n",
      "Epoch:  9 Batch:  0 Loss:  0.01326172985136509\n",
      "Epoch:  9 Batch:  100 Loss:  0.0019182285759598017\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    model = CNN_Gate_Aspect_Text(torch.Tensor(embedding_matrix).to(dtype=torch.long), 3, 100, [3, 4, 5], torch.Tensor(ac_embedding_matrix).to(dtype=torch.long))\n",
    "    # model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "\n",
    "    for epoch in range(10):\n",
    "        for i, data in enumerate(train_batches):\n",
    "            sentence = data[:, :-2]\n",
    "            aspect = data[:, -2]\n",
    "            sentiment = data[:, -1]\n",
    "\n",
    "            # print(sentence.shape)\n",
    "            # print(aspect.shape)\n",
    "            # print(sentiment.shape)\n",
    "\n",
    "            # for i in range(len(sentence)):\n",
    "            #     print(tokens_to_string(sentence[i].to(dtype=torch.long, device='cpu')))\n",
    "            #     print(ac_idx2word[aspect[i].to(dtype=torch.long, device='cpu')])\n",
    "            #     print(sentiment[i])\n",
    "\n",
    "            # print(aspect[0])\n",
    "\n",
    "            # x = x.to(device)\n",
    "            # y = y.to(device)\n",
    "            # optimizer.zero_grad()\n",
    "            model.zero_grad()\n",
    "            # model.zero_grad()\n",
    "            # convert sentence to int tensor\n",
    "            sentence = sentence.to(dtype=torch.long)\n",
    "            aspect = aspect.to(dtype=torch.long)\n",
    "            \n",
    "            logit, x, y = model(sentence, aspect)\n",
    "            # y = torch.tensor(y)\n",
    "            loss = loss_function(logit, sentiment)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print('Epoch: ', epoch, 'Batch: ', i, 'Loss: ', loss.item())\n",
    "            \n",
    "    return model\n",
    "\n",
    "model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\srisa\\Desktop\\Desktop files\\Project\\SMAI-Project-Team28\\smai.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X52sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m sentence \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(sentence)\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X52sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m aspect \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(aspect)\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X52sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m prediction \u001b[39m=\u001b[39m model(sentence, aspect)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X52sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# get the class with the highest score\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X52sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m prediction \u001b[39m=\u001b[39m prediction\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\srisa\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\srisa\\Desktop\\Desktop files\\Project\\SMAI-Project-Team28\\smai.ipynb Cell 35\u001b[0m in \u001b[0;36mCNN_Gate_Aspect_Text.forward\u001b[1;34m(self, feature, aspect)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X52sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m aspect_v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maspect_embed(aspect)  \u001b[39m# (N, L', D)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X52sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# aspect_v = aspect_v.sum(1) / aspect_v.size(1)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X52sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m x \u001b[39m=\u001b[39m [F\u001b[39m.\u001b[39mtanh(conv(feature\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m))) \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs1]  \u001b[39m# [(N,Co,L), ...]*len(Ks)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X52sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m y \u001b[39m=\u001b[39m [F\u001b[39m.\u001b[39mrelu(conv(feature\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_aspect(aspect_v)\u001b[39m.\u001b[39munsqueeze(\u001b[39m2\u001b[39m)) \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs2]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X52sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m x \u001b[39m=\u001b[39m [i\u001b[39m*\u001b[39mj \u001b[39mfor\u001b[39;00m i, j \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(x, y)]\n",
      "\u001b[1;32mc:\\Users\\srisa\\Desktop\\Desktop files\\Project\\SMAI-Project-Team28\\smai.ipynb Cell 35\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X52sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m aspect_v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maspect_embed(aspect)  \u001b[39m# (N, L', D)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X52sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# aspect_v = aspect_v.sum(1) / aspect_v.size(1)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X52sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m x \u001b[39m=\u001b[39m [F\u001b[39m.\u001b[39mtanh(conv(feature\u001b[39m.\u001b[39;49mtranspose(\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m))) \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs1]  \u001b[39m# [(N,Co,L), ...]*len(Ks)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X52sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m y \u001b[39m=\u001b[39m [F\u001b[39m.\u001b[39mrelu(conv(feature\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_aspect(aspect_v)\u001b[39m.\u001b[39munsqueeze(\u001b[39m2\u001b[39m)) \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs2]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/srisa/Desktop/Desktop%20files/Project/SMAI-Project-Team28/smai.ipynb#X52sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m x \u001b[39m=\u001b[39m [i\u001b[39m*\u001b[39mj \u001b[39mfor\u001b[39;00m i, j \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(x, y)]\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "def evaluate(model, x_test):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "063993497d7afc17216208e6d2fa098ad08ff0cdca94ee4cdde88ee1996574e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
